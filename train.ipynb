{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/anaconda3/envs/mlops/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/AITA-Reddit-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(model_name, num_labels=4, problem_type='multi_label_classification').to('cuda')\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(model_name, problem_type='multi_label_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 15:01:40.866243: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-07 15:01:40.866276: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-07 15:01:40.866307: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-07 15:01:40.872060: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-07 15:01:41.554115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "classifier = transformers.pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/anaconda3/envs/mlops/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n",
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "# Create Dataset\n",
    "base_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Vectorize labels\n",
    "cols = base_dataset.column_names\n",
    "base_dataset = base_dataset.map(lambda x: {'labels': [x[c] for c in cols if c != \"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize the data (only keep relevant columns)\n",
    "cols = base_dataset.column_names\n",
    "cols.remove('labels')\n",
    "dataset = base_dataset.select(range(1000)).map(tokenize_function, batched=True, remove_columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset class with LABEL and TEXT columns\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "validation_test_dataset = dataset['test'].train_test_split(test_size=0.5)\n",
    "dataset['validation'] = validation_test_dataset['train']\n",
    "dataset['test'] = validation_test_dataset['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "def compute_metrics(pred):\n",
    "    print(pred)\n",
    "    # labels = pred.label_ids\n",
    "    # preds = pred.predictions.argmax(-1)\n",
    "    # precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 102/800 [00:09<01:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5525, 'learning_rate': 1e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 202/800 [00:17<00:52, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3463, 'learning_rate': 2e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 302/800 [00:26<00:43, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2659, 'learning_rate': 3e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 402/800 [00:35<00:34, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4349, 'learning_rate': 4e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 500/800 [00:44<00:26, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3404, 'learning_rate': 5e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 62%|██████▎   | 500/800 [00:46<00:26, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4446331858634949, 'eval_runtime': 2.0251, 'eval_samples_per_second': 49.381, 'eval_steps_per_second': 49.381, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 602/800 [00:56<00:17, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3369, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 702/800 [01:05<00:08, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3399, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [01:14<00:00, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2722, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 74.0231, 'train_samples_per_second': 10.807, 'train_steps_per_second': 10.807, 'train_loss': 0.3611268949508667, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=0.3611268949508667, metrics={'train_runtime': 74.0231, 'train_samples_per_second': 10.807, 'train_steps_per_second': 10.807, 'train_loss': 0.3611268949508667, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune the model\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=1,              # total number of training epochs\n",
    "    per_device_train_batch_size=1,   # batch size per device during training\n",
    "    per_device_eval_batch_size=1,    # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    ")\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    ")\n",
    "trainer.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 49.37it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.951932 , -6.9526587,  3.887982 , -3.9039557],\n",
       "       [-6.993805 , -6.9506974,  3.8821592, -3.8811848],\n",
       "       [-6.949279 , -6.9518375,  3.884804 , -3.895899 ],\n",
       "       [-7.0172915, -6.963989 ,  3.8609831, -3.800006 ],\n",
       "       [-6.9388247, -6.937853 ,  3.881006 , -3.903065 ],\n",
       "       [-6.951508 , -6.942781 ,  3.869922 , -3.8835871],\n",
       "       [-6.953735 , -6.9412117,  3.8831904, -3.897611 ],\n",
       "       [-6.9593654, -6.9604626,  3.8821692, -3.887351 ],\n",
       "       [-6.983482 , -6.9581547,  3.8893023, -3.8764007],\n",
       "       [-6.9636717, -6.9517174,  3.8869858, -3.8900533],\n",
       "       [-6.9386563, -6.941848 ,  3.8772767, -3.8985894],\n",
       "       [-6.953829 , -6.9445796,  3.8808029, -3.8921132],\n",
       "       [-6.9491177, -6.945044 ,  3.882238 , -3.8968878],\n",
       "       [-6.9426227, -6.9393888,  3.8759377, -3.899986 ],\n",
       "       [-6.9623795, -6.9431124,  3.880493 , -3.8903496],\n",
       "       [-6.9543047, -6.9564753,  3.8864276, -3.895424 ],\n",
       "       [-6.9406095, -6.935857 ,  3.8835394, -3.8993976],\n",
       "       [-7.0017557, -6.962772 ,  3.878589 , -3.8556468],\n",
       "       [-6.8152814, -6.7767367,  3.6189291, -3.586858 ],\n",
       "       [-7.009014 , -6.9616795,  3.873215 , -3.8507574],\n",
       "       [-7.0043783, -6.95954  ,  3.8660462, -3.817784 ],\n",
       "       [-6.981021 , -6.950383 ,  3.8796718, -3.8723743],\n",
       "       [-6.9463363, -6.9408417,  3.8768852, -3.900716 ],\n",
       "       [-6.9917026, -6.936306 ,  3.8670275, -3.852482 ],\n",
       "       [-6.9653773, -6.8598056,  3.7751517, -3.7241666],\n",
       "       [-6.967841 , -6.9472456,  3.8823454, -3.8766418],\n",
       "       [-6.94858  , -6.942689 ,  3.8886082, -3.8967235],\n",
       "       [-6.9573927, -6.947627 ,  3.8870003, -3.8926709],\n",
       "       [-6.977355 , -6.9226866,  3.841255 , -3.8179402],\n",
       "       [-6.9999294, -6.961104 ,  3.878124 , -3.8441484],\n",
       "       [-6.949775 , -6.9472313,  3.885389 , -3.8958812],\n",
       "       [-6.9791822, -6.9464254,  3.8650362, -3.8597562],\n",
       "       [-6.9619   , -6.9367924,  3.8904235, -3.8895905],\n",
       "       [-6.943626 , -6.9490457,  3.8879206, -3.9047294],\n",
       "       [-6.9973526, -6.9514556,  3.8729794, -3.85964  ],\n",
       "       [-6.991819 , -6.8772483,  3.7599785, -3.7097375],\n",
       "       [-6.9509287, -6.934077 ,  3.8798044, -3.898989 ],\n",
       "       [-6.974146 , -6.951774 ,  3.8775938, -3.8593073],\n",
       "       [-7.009367 , -6.9466147,  3.8511112, -3.7815459],\n",
       "       [-6.959959 , -6.94637  ,  3.883568 , -3.8873556],\n",
       "       [-6.9590387, -6.959078 ,  3.8876698, -3.8921008],\n",
       "       [-6.9695506, -6.953583 ,  3.8871434, -3.880053 ],\n",
       "       [-6.9881973, -6.966388 ,  3.8974001, -3.8822556],\n",
       "       [-6.9563017, -6.949536 ,  3.879607 , -3.8974392],\n",
       "       [-6.915949 , -6.8555274,  3.750839 , -3.7077432],\n",
       "       [-6.9497895, -6.949182 ,  3.8839042, -3.8932035],\n",
       "       [-7.0073147, -6.9333086,  3.8345578, -3.7844627],\n",
       "       [-6.9842257, -6.948421 ,  3.8880658, -3.879436 ],\n",
       "       [-6.9740148, -6.9487867,  3.8833742, -3.8701186],\n",
       "       [-6.9536166, -6.9499526,  3.8846188, -3.8975704],\n",
       "       [-6.9452505, -6.936503 ,  3.8822532, -3.9039953],\n",
       "       [-7.0003033, -6.9434214,  3.8643572, -3.8374598],\n",
       "       [-6.9832373, -6.954016 ,  3.876677 , -3.8658917],\n",
       "       [-7.00379  , -6.9482517,  3.8553684, -3.8259661],\n",
       "       [-6.971779 , -6.964251 ,  3.8803341, -3.8847945],\n",
       "       [-7.0035443, -6.966621 ,  3.8820155, -3.8532765],\n",
       "       [-6.9426966, -6.956964 ,  3.8818295, -3.8979516],\n",
       "       [-6.9774046, -6.9668455,  3.8942876, -3.8829398],\n",
       "       [-6.9386806, -6.9405303,  3.878449 , -3.9010208],\n",
       "       [-6.9879885, -6.9552755,  3.8495948, -3.8158467],\n",
       "       [-6.95022  , -6.9473295,  3.8793452, -3.8983111],\n",
       "       [-6.953169 , -6.944215 ,  3.8789403, -3.9010975],\n",
       "       [-6.9481635, -6.9414196,  3.8867254, -3.907168 ],\n",
       "       [-6.9897003, -6.941915 ,  3.871042 , -3.8378646],\n",
       "       [-7.0067596, -6.9223256,  3.8557262, -3.83799  ],\n",
       "       [-7.0116844, -6.9531026,  3.842244 , -3.802883 ],\n",
       "       [-6.995379 , -6.9580035,  3.8857238, -3.852472 ],\n",
       "       [-6.953588 , -6.94816  ,  3.884569 , -3.8930628],\n",
       "       [-6.984543 , -6.9599853,  3.8812277, -3.8574228],\n",
       "       [-6.9527397, -6.948007 ,  3.8811631, -3.8863552],\n",
       "       [-6.995407 , -6.956529 ,  3.8765674, -3.8397257],\n",
       "       [-6.959585 , -6.9516754,  3.8872652, -3.8978453],\n",
       "       [-6.9755025, -6.967422 ,  3.885768 , -3.8761475],\n",
       "       [-6.9748325, -6.9529014,  3.9002256, -3.8845375],\n",
       "       [-6.9767265, -6.9374275,  3.8672063, -3.862848 ],\n",
       "       [-6.95339  , -6.9371037,  3.8837295, -3.8901417],\n",
       "       [-6.9614754, -6.947825 ,  3.8856432, -3.8921893],\n",
       "       [-6.9705677, -6.950177 ,  3.875947 , -3.8871014],\n",
       "       [-6.981131 , -6.960953 ,  3.887986 , -3.8708453],\n",
       "       [-6.9432926, -6.9446354,  3.8841927, -3.89729  ],\n",
       "       [-6.943037 , -6.9389224,  3.8875248, -3.8975513],\n",
       "       [-6.9764323, -6.9615264,  3.8974006, -3.883368 ],\n",
       "       [-7.00467  , -6.9614477,  3.8546503, -3.8301   ],\n",
       "       [-6.96408  , -6.946715 ,  3.8821087, -3.8752968],\n",
       "       [-6.9818892, -6.8815846,  3.7974389, -3.7111752],\n",
       "       [-6.9185505, -6.9358134,  3.8754804, -3.9046192],\n",
       "       [-7.0070624, -6.9606905,  3.881529 , -3.8567646],\n",
       "       [-6.9430156, -6.942676 ,  3.888477 , -3.9001653],\n",
       "       [-6.94766  , -6.9380884,  3.8790684, -3.8932118],\n",
       "       [-6.9319334, -6.8516374,  3.7301364, -3.7052546],\n",
       "       [-6.9349756, -6.937066 ,  3.8796413, -3.8972623],\n",
       "       [-6.9377875, -6.8538547,  3.7267373, -3.6675406],\n",
       "       [-6.9306154, -6.9271536,  3.87451  , -3.8988168],\n",
       "       [-6.9573836, -6.949156 ,  3.8888338, -3.8969514],\n",
       "       [-6.983526 , -6.9167404,  3.792202 , -3.7175887],\n",
       "       [-6.943499 , -6.9302716,  3.8849065, -3.904668 ],\n",
       "       [-6.943685 , -6.9458733,  3.888055 , -3.8976166],\n",
       "       [-6.985785 , -6.9663606,  3.8644645, -3.8420477],\n",
       "       [-6.9720354, -6.9519444,  3.8870776, -3.8862572],\n",
       "       [-6.8492045, -6.794022 ,  3.6876116, -3.615836 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
